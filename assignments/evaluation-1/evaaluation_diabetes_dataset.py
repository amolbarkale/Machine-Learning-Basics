# -*- coding: utf-8 -*-
"""evaaluation-diabetes-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fXxOFnGLn277dybs8hQVXRAhkTR1asVW
"""

pip install pandas numpy matplotlib seaborn

import pandas as pd
# 1] EDA
df = pd.read_csv('diabetes.csv')
df

df.info()

df.describe()

#isnull values in all columns
df.isnull().sum()

# Range all values of insulin column in by deviding with 10
import numpy as np

# Test with log conversion ->
# df['Insulin'] = df['Insulin'].apply(lambda x: np.log(x) if x != 0 else 0)

# Test with log float conversion ->
df['Insulin'] = df['Insulin'].apply(lambda x: x/10 if x != 0 else 0)

df

# split data in tran and test
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score


X = df.drop('Outcome', axis=1)

y = df['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = LogisticRegression()

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("LOGISTIC REGRESSION => \n")
print("Accuracy:", accuracy)
precison = precision_score(y_test, y_pred)
print("Precision:", precison)
recall = recall_score(y_test, y_pred)
print("Recall:", recall)
confusion_mtcx = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", confusion_mtcx)
roc_auc = roc_auc_score(y_test, y_pred)
print("ROC AUC:", roc_auc)

# perform Decision tree classifier
from sklearn.tree import DecisionTreeClassifier

from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score

X = df.drop('Outcome', axis=1)

y = df['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = DecisionTreeClassifier()

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Decision TREE => \n")
print("Accuracy:", accuracy)
precison = precision_score(y_test, y_pred)
print("Precision:", precison)
recall = recall_score(y_test, y_pred)
print("Recall:", recall)
confusion_mtcx = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", confusion_mtcx)
roc_auc = roc_auc_score(y_test, y_pred)
print("ROC AUC:", roc_auc)

"""# Compare the Decision Tree's interpretability vs. Logistic Regressionâ€™s coefficients.

=> In above case test metrics of Logisitc regression model performed slight better but ROC AUC matrix is quite similar.

LOGISTIC REGRESSION =>

Accuracy: 0.7359307359307359,
Precision: 0.6172839506172839,
Recall: 0.625,
Confusion Matrix:
 [[120  31]
 [ 30  50]],
ROC AUC: 0.7098509933774835.

Decision TREE =>

Accuracy: 0.7186147186147186,
Precision: 0.5789473684210527,
Recall: 0.6875,
Confusion Matrix:
 [[111  40]
 [ 25  55]],
ROC AUC: 0.7112996688741722

# Which one would you prefer in a medical diagnosis scenario? Why?

=> As per the above observation Logistic Regression is slighly outperforing over Dicision Tree BUT as per my knowledge the understanding of nodes for the given features should be hghier for Decisino Tree algorithm so, I would re-verify the input features with experiments and will take expert suggestion for what to choose in Medical Diagnosis Scenerio.

## Comparison & Reflection
## Compare Logistic Regression and Decision Tree results (accuracy, precision, recall, F1, AUC).

# Discuss:

# Which model performs better?
=> In above case the Logisitic Regression model performed well but it is a small metrics difference

# Which model is easier to interpret for doctors?
=> As per my observation from above experiment, both models were easy to train and predict

# If the dataset is slightly imbalanced (more 0's than 1's), which metric (Precision or Recall) should be prioritized in diagnosing diabetes? Why?
=> If there is imbalanced data specially (more 0's than 1's) then we should prioritize Recall metrics in that case.

I am not able to recollect the exact reason but the best example where we can priritize Recall value is email spam where most of the time emails will be not spammed but still we have to consider spammy emails and avoid False Positives.
"""

