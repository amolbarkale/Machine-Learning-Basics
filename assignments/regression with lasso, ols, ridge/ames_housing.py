# -*- coding: utf-8 -*-
"""Ames housing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BzCtQRR87okndfoXzDjZIfH_DbESK8mf
"""

# Commented out IPython magic to ensure Python compatibility.
# Install necessary libraries
# %pip install pandas numpy scikit-learn

# Import necessary libraries and modules
import pandas as pd
import numpy as np
from sklearn.linear_model import Lasso, Ridge
from sklearn.linear_model import LinearRegression as OLS

# Load the dataset
df = pd.read_csv('./AmesHousing.csv')

df = df.drop_duplicates().reset_index(drop=True)

# Remove 'pids' and 'order' features
df = df.drop(['PID', 'Order'], axis=1)

# Display the first few rows to verify the changes
display(df.head())

# Check for missing values and sum them up for each column
missing_values = df.isnull().sum()

# Display the columns with missing values and their counts
display(missing_values[missing_values > 0])

# Identify categorical and numerical columns
categorical_cols = df.select_dtypes(include=['object', 'category']).columns
numerical_cols = df.select_dtypes(include=np.number).columns

# Fill missing values
df[categorical_cols] = df[categorical_cols].fillna('None')
df[numerical_cols] = df[numerical_cols].fillna(0)

# Verify that there are no more missing values
display(df.isnull().sum()[df.isnull().sum() > 0])

# Impute 'Lot Frontage' with median per 'Neighborhood'
if 'Lot Frontage' in df.columns:
    df['Lot Frontage'] = df.groupby('Neighborhood')['Lot Frontage'].transform(lambda x: x.fillna(x.median()))

if 'Mas Vnr Area' in df.columns and df['Mas Vnr Area'].dtype != 'object':
    df.loc[df['Mas Vnr Type'] == 'None', 'Mas Vnr Area'] = 0
    df['Mas Vnr Area'] = df['Mas Vnr Area'].fillna(0) # Fill any remaining numerical Mas Vnr Area NAs with 0

if 'Garage Yr Blt' in df.columns:
    df.loc[df['Garage Type'] == 'None', 'Garage Yr Blt'] = 0
    df['Garage Yr Blt'] = df['Garage Yr Blt'].fillna(df['Year Built']) # Fill remaining with Year Built if still NA

remaining_na = df.isnull().sum()[df.isnull().sum() > 0]
if not remaining_na.empty:
    print("\nWarning: Some NA values still exist after primary imputation:")
    print(remaining_na)
    # Final catch-all for any straggling NAs (e.g., in newly created features or if a column was missed)
    for col in remaining_na.index:
        if df[col].dtype == 'object':
            df[col] = df[col].fillna(df[col].mode()[0])
        else:
            df[col] = df[col].fillna(df[col].median())



import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation matrix
correlation_matrix = df[numerical_cols].corr()

# Create a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)
plt.title('Heatmap of Feature Collinearity')
plt.show()



# Train Lasso model
lasso_model = Lasso()
lasso_model.fit(X_train, y_train)

# Predict on the test set
y_pred_lasso = lasso_model.predict(X_test)

# Evaluate Lasso model
rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))
mae_lasso = mean_absolute_error(y_test, y_pred_lasso)
r2_lasso = r2_score(y_test, y_pred_lasso)

print("Lasso Model Performance:")
print(f"RMSE: {rmse_lasso}")
print(f"MAE: {mae_lasso}")
print(f"R-squared: {r2_lasso}")



# Train Ridge model
ridge_model = Ridge()
ridge_model.fit(X_train, y_train)

# Predict on the test set
y_pred_ridge = ridge_model.predict(X_test)

# Evaluate Ridge model
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
mae_ridge = mean_absolute_error(y_test, y_pred_ridge)
r2_ridge = r2_score(y_test, y_pred_ridge)

print("Ridge Model Performance:")
print(f"RMSE: {rmse_ridge}")
print(f"MAE: {mae_ridge}")
print(f"R-squared: {r2_ridge}")